{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dcc2b3a",
   "metadata": {},
   "source": [
    "## Experimento 11  ‚Äî Compara√ß√£o de Modelos + GridSearchCV\n",
    "\n",
    "**Objetivo did√°tico:** mostrar duas etapas complementares de sele√ß√£o de modelos:\n",
    "1) **Parte 1 (Baseline, sem GridSearch):** comparar modelos com *defaults* bem escolhidos, usando `Pipeline` e valida√ß√£o cruzada estratificada.\n",
    "2) **Parte 2 (Com GridSearchCV):** sintonizar hiperpar√¢metros dos **mesmos classificadores**, comparar por CV e avaliar no teste, salvando o melhor.\n",
    "\n",
    "> No *Iris*, modelos lineares costumam ir muito bem. √â esperado que o baseline seja forte e, √†s vezes, at√© supere o resultado do GridSearch quando o *grid* est√° conservador.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90c6cc1",
   "metadata": {},
   "source": [
    "### üéØ Objetivos de aprendizagem\n",
    "- Evitar *data leakage* com `Pipeline` + `StandardScaler` quando apropriado.\n",
    "- Comparar classificadores sob o mesmo esquema de valida√ß√£o cruzada.\n",
    "- Entender quando *defaults* j√° s√£o muito bons.\n",
    "- Usar `GridSearchCV` de forma consistente com os mesmos modelos do baseline.\n",
    "- Registrar resultados em tabelas para facilitar a an√°lise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc64a0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== Configura√ß√£o Inicial ==============\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Dados\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "# Esquema de CV consistente nas duas partes\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cc9f38",
   "metadata": {},
   "source": [
    "## Parte 1 ‚Äî Baseline consistente (sem GridSearch)\n",
    "- **Mesmos modelos** usados depois no GridSearch: `LogReg`, `SVC (linear)`, `RandomForest`.\n",
    "- `Pipeline` + `StandardScaler` em LogReg e SVC (evita *data leakage*).\n",
    "- Compara√ß√£o por **CV estratificada** (m√©dia ¬± desvio) e avalia√ß√£o no **teste**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41ed3d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        model  cv_mean_acc  cv_std_acc  test_acc\n",
      "0  SVC_linear     0.975000    0.033333  1.000000\n",
      "1      LogReg     0.958333    0.026352  0.933333\n",
      "2          RF     0.950000    0.031180  0.900000\n",
      "\n",
      "== Melhor por CV (sem GridSearch): SVC_linear ==\n",
      "Acur√°cia no teste: 1.000\n",
      "\n",
      "Relat√≥rio de classifica√ß√£o:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00        10\n",
      "           2       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "Matriz de confus√£o:\n",
      " [[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n"
     ]
    }
   ],
   "source": [
    "# Candidatos (sem GridSearch)\n",
    "candidates = {\n",
    "    \"LogReg\": Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", LogisticRegression(max_iter=2000, random_state=RANDOM_STATE))\n",
    "    ]),\n",
    "    \"SVC_linear\": Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", SVC(kernel=\"linear\", random_state=RANDOM_STATE))\n",
    "    ]),\n",
    "    \"RF\": RandomForestClassifier(n_estimators=200, random_state=RANDOM_STATE)\n",
    "}\n",
    "\n",
    "rows = []\n",
    "for name, model in candidates.items():\n",
    "    cv_res = cross_validate(\n",
    "        model, X_train, y_train,\n",
    "        cv=cv, scoring=\"accuracy\",\n",
    "        return_train_score=False, n_jobs=-1\n",
    "    )\n",
    "    cv_mean = cv_res[\"test_score\"].mean()\n",
    "    cv_std  = cv_res[\"test_score\"].std()\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    test_acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    rows.append({\"model\": name, \"cv_mean_acc\": cv_mean, \"cv_std_acc\": cv_std, \"test_acc\": test_acc})\n",
    "\n",
    "df_base = pd.DataFrame(rows).sort_values(by=\"cv_mean_acc\", ascending=False).reset_index(drop=True)\n",
    "print(df_base)\n",
    "\n",
    "best_name = df_base.iloc[0][\"model\"]\n",
    "best_model_baseline = candidates[best_name]\n",
    "print(f\"\\n== Melhor por CV (sem GridSearch): {best_name} ==\")\n",
    "\n",
    "# Relat√≥rio do melhor baseline\n",
    "best_model_baseline.fit(X_train, y_train)\n",
    "y_pred_best = best_model_baseline.predict(X_test)\n",
    "print(f\"Acur√°cia no teste: {accuracy_score(y_test, y_pred_best):.3f}\\n\")\n",
    "print(\"Relat√≥rio de classifica√ß√£o:\\n\", classification_report(y_test, y_pred_best))\n",
    "print(\"Matriz de confus√£o:\\n\", confusion_matrix(y_test, y_pred_best))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d7c1b6",
   "metadata": {},
   "source": [
    "## Parte 2 ‚Äî Sintoniza√ß√£o com GridSearchCV (mesmos modelos)\n",
    "- Mantemos **os mesmos tr√™s classificadores** do baseline.\n",
    "- Usamos **grids enxutos e razo√°veis** para n√£o superexplorar o Iris, mas suficientes para demonstrar tuning.\n",
    "- Crit√©rio de sele√ß√£o: **maior `cv_mean_acc`**.\n",
    "- Avaliamos no teste e salvamos o **melhor modelo**.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
