{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dcc2b3a",
   "metadata": {},
   "source": [
    "## Experimento 11  ‚Äî Compara√ß√£o de Modelos + GridSearchCV\n",
    "\n",
    "**Objetivo did√°tico:** mostrar duas etapas complementares de sele√ß√£o de modelos:\n",
    "1) **Parte 1 (Baseline, sem GridSearch):** comparar modelos com *defaults* bem escolhidos, usando `Pipeline` e valida√ß√£o cruzada estratificada.\n",
    "2) **Parte 2 (Com GridSearchCV):** sintonizar hiperpar√¢metros dos **mesmos classificadores**, comparar por CV e avaliar no teste, salvando o melhor.\n",
    "\n",
    "> No *Iris*, modelos lineares costumam ir muito bem. √â esperado que o baseline seja forte e, √†s vezes, at√© supere o resultado do GridSearch quando o *grid* est√° conservador.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b419a47b",
   "metadata": {},
   "source": [
    "[![Abrir no Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/flavioluizseixas/aprendizado-de-maquina-na-saude/blob/main/0-Nivelamento/Experimento_11.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90c6cc1",
   "metadata": {},
   "source": [
    "### üéØ Objetivos de aprendizagem\n",
    "- Evitar *data leakage* com `Pipeline` + `StandardScaler` quando apropriado.\n",
    "- Comparar classificadores sob o mesmo esquema de valida√ß√£o cruzada.\n",
    "- Entender quando *defaults* j√° s√£o muito bons.\n",
    "- Usar `GridSearchCV` de forma consistente com os mesmos modelos do baseline.\n",
    "- Registrar resultados em tabelas para facilitar a an√°lise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc64a0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== Configura√ß√£o Inicial ==============\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Dados\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "# Esquema de CV consistente nas duas partes\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cc9f38",
   "metadata": {},
   "source": [
    "## Parte 1 ‚Äî Baseline consistente (sem GridSearch)\n",
    "- **Mesmos modelos** usados depois no GridSearch: `LogReg`, `SVC (linear)`, `RandomForest`.\n",
    "- `Pipeline` + `StandardScaler` em LogReg e SVC (evita *data leakage*).\n",
    "- Compara√ß√£o por **CV estratificada** (m√©dia ¬± desvio) e avalia√ß√£o no **teste**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41ed3d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        model  cv_mean_acc  cv_std_acc  test_acc\n",
      "0  SVC_linear     0.975000    0.033333  1.000000\n",
      "1      LogReg     0.958333    0.026352  0.933333\n",
      "2          RF     0.950000    0.031180  0.900000\n",
      "\n",
      "== Melhor por CV (sem GridSearch): SVC_linear ==\n",
      "Acur√°cia no teste: 1.000\n",
      "\n",
      "Relat√≥rio de classifica√ß√£o:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00        10\n",
      "           2       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "Matriz de confus√£o:\n",
      " [[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n"
     ]
    }
   ],
   "source": [
    "# Candidatos (sem GridSearch)\n",
    "candidates = {\n",
    "    \"LogReg\": Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", LogisticRegression(max_iter=2000, random_state=RANDOM_STATE))\n",
    "    ]),\n",
    "    \"SVC_linear\": Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", SVC(kernel=\"linear\", random_state=RANDOM_STATE))\n",
    "    ]),\n",
    "    \"RF\": RandomForestClassifier(n_estimators=200, random_state=RANDOM_STATE)\n",
    "}\n",
    "\n",
    "rows = []\n",
    "for name, model in candidates.items():\n",
    "    cv_res = cross_validate(\n",
    "        model, X_train, y_train,\n",
    "        cv=cv, scoring=\"accuracy\",\n",
    "        return_train_score=False, n_jobs=-1\n",
    "    )\n",
    "    cv_mean = cv_res[\"test_score\"].mean()\n",
    "    cv_std  = cv_res[\"test_score\"].std()\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    test_acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    rows.append({\"model\": name, \"cv_mean_acc\": cv_mean, \"cv_std_acc\": cv_std, \"test_acc\": test_acc})\n",
    "\n",
    "df_base = pd.DataFrame(rows).sort_values(by=\"cv_mean_acc\", ascending=False).reset_index(drop=True)\n",
    "print(df_base)\n",
    "\n",
    "best_name = df_base.iloc[0][\"model\"]\n",
    "best_model_baseline = candidates[best_name]\n",
    "print(f\"\\n== Melhor por CV (sem GridSearch): {best_name} ==\")\n",
    "\n",
    "# Relat√≥rio do melhor baseline\n",
    "best_model_baseline.fit(X_train, y_train)\n",
    "y_pred_best = best_model_baseline.predict(X_test)\n",
    "print(f\"Acur√°cia no teste: {accuracy_score(y_test, y_pred_best):.3f}\\n\")\n",
    "print(\"Relat√≥rio de classifica√ß√£o:\\n\", classification_report(y_test, y_pred_best))\n",
    "print(\"Matriz de confus√£o:\\n\", confusion_matrix(y_test, y_pred_best))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d7c1b6",
   "metadata": {},
   "source": [
    "## Parte 2 ‚Äî Sintoniza√ß√£o com GridSearchCV (mesmos modelos)\n",
    "- Mantemos **os mesmos tr√™s classificadores** do baseline.\n",
    "- Usamos **grids enxutos e razo√°veis** para n√£o superexplorar o Iris, mas suficientes para demonstrar tuning.\n",
    "- Crit√©rio de sele√ß√£o: **maior `cv_mean_acc`**.\n",
    "- Avaliamos no teste e salvamos o **melhor modelo**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c063681f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        model                                        best_params  cv_mean_acc  \\\n",
      "0  SVC_linear                                    {'clf__C': 0.1}     0.975000   \n",
      "1      LogReg  {'clf__C': 3, 'clf__penalty': 'l2', 'clf__solv...     0.966667   \n",
      "2          RF  {'max_depth': None, 'min_samples_split': 5, 'n...     0.966667   \n",
      "\n",
      "   test_acc  \n",
      "0  0.933333  \n",
      "1  0.966667  \n",
      "2  0.966667  \n",
      "\n",
      "== Melhor por CV (com GridSearch): SVC_linear ==\n",
      "Acur√°cia no teste: 0.933\n",
      "\n",
      "Relat√≥rio de classifica√ß√£o:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       0.90      0.90      0.90        10\n",
      "           2       0.90      0.90      0.90        10\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.93      0.93      0.93        30\n",
      "weighted avg       0.93      0.93      0.93        30\n",
      "\n",
      "Matriz de confus√£o:\n",
      " [[10  0  0]\n",
      " [ 0  9  1]\n",
      " [ 0  1  9]]\n",
      "\n",
      "Modelo salvo em melhor_modelo_exp11_final.joblib\n"
     ]
    }
   ],
   "source": [
    "# Pipelines e grids\n",
    "pipe_logreg = Pipeline([(\"scaler\", StandardScaler()), (\"clf\", LogisticRegression(max_iter=2000, random_state=RANDOM_STATE))])\n",
    "grid_logreg = {\n",
    "    \"clf__C\": [0.1, 1, 3, 10],\n",
    "    \"clf__penalty\": [\"l2\"],\n",
    "    \"clf__solver\": [\"lbfgs\", \"liblinear\"],\n",
    "}\n",
    "\n",
    "pipe_svc_lin = Pipeline([(\"scaler\", StandardScaler()), (\"clf\", SVC(kernel=\"linear\", random_state=RANDOM_STATE))])\n",
    "grid_svc_lin = {\"clf__C\": [0.1, 1, 3, 10]}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "grid_rf = {\n",
    "    \"n_estimators\": [100, 200, 400],\n",
    "    \"max_depth\": [None, 5, 10],\n",
    "    \"min_samples_split\": [2, 5],\n",
    "}\n",
    "\n",
    "search_space = [\n",
    "    (\"LogReg\",    pipe_logreg, grid_logreg),\n",
    "    (\"SVC_linear\", pipe_svc_lin, grid_svc_lin),\n",
    "    (\"RF\",        rf,          grid_rf),\n",
    "]\n",
    "\n",
    "results = []\n",
    "best_global = None\n",
    "best_global_name = None\n",
    "best_global_cv = -np.inf\n",
    "\n",
    "for name, estimator, param_grid in search_space:\n",
    "    gs = GridSearchCV(\n",
    "        estimator=estimator,\n",
    "        param_grid=param_grid,\n",
    "        cv=cv,\n",
    "        scoring=\"accuracy\",\n",
    "        n_jobs=-1,\n",
    "        refit=True,\n",
    "        return_train_score=False,\n",
    "    )\n",
    "    gs.fit(X_train, y_train)\n",
    "    y_pred = gs.best_estimator_.predict(X_test)\n",
    "    test_acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    results.append({\n",
    "        \"model\": name,\n",
    "        \"best_params\": gs.best_params_,\n",
    "        \"cv_mean_acc\": gs.best_score_,\n",
    "        \"test_acc\": test_acc\n",
    "    })\n",
    "\n",
    "    if gs.best_score_ > best_global_cv:\n",
    "        best_global_cv = gs.best_score_\n",
    "        best_global = gs.best_estimator_\n",
    "        best_global_name = name\n",
    "\n",
    "df_gs = pd.DataFrame(results).sort_values(by=\"cv_mean_acc\", ascending=False).reset_index(drop=True)\n",
    "print(df_gs)\n",
    "\n",
    "print(f\"\\n== Melhor por CV (com GridSearch): {best_global_name} ==\")\n",
    "y_pred_best = best_global.predict(X_test)\n",
    "print(f\"Acur√°cia no teste: {accuracy_score(y_test, y_pred_best):.3f}\\n\")\n",
    "print(\"Relat√≥rio de classifica√ß√£o:\\n\", classification_report(y_test, y_pred_best))\n",
    "print(\"Matriz de confus√£o:\\n\", confusion_matrix(y_test, y_pred_best))\n",
    "\n",
    "import os\n",
    "\n",
    "joblib.dump(best_global, \"melhor_modelo_exp11_final.joblib\")\n",
    "print(\"\\nModelo salvo em melhor_modelo_exp11_final.joblib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da56770d",
   "metadata": {},
   "source": [
    "### üß† Discuss√£o r√°pida\n",
    "- Em *datasets* simples como o **Iris**, **SVC linear** frequentemente j√° performa muito bem com *defaults*.\n",
    "- **GridSearch** √© mais valioso em problemas **maiores/complexos**, com mais ru√≠do e hiperpar√¢metros sens√≠veis.\n",
    "- Use **tabelas consolidadas** (como `df_base` e `df_gs`) para justificar escolhas e **rastrear** configura√ß√µes.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
