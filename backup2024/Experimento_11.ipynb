{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cda97917",
   "metadata": {},
   "source": [
    "## Experimento 11 — Comparando Modelos (NB, SVM, KNN)\n",
    "**Objetivo:** comparar modelos simples em um dataset clássico e acrescentar otimização dos hiperparâmetros\n",
    "\n",
    "### Enunciado\n",
    "1. Carregue o dataset **Iris** e separe em treino e teste (80/20) com `stratify`.\n",
    "2. Realize uma **busca de modelo** simples comparando **LogisticRegression**, **SVC (linear)** e **RandomForest** com validação cruzada (k=5).  \n",
    "3. **Tarefa Extra:** acrescente uma **busca de hiperparâmetros** com `GridSearchCV` para, pelo menos, dois modelos (ex.: SVC e RandomForest) usando `Pipeline` com `StandardScaler` quando necessário.  \n",
    "4. Avalie no conjunto de teste o melhor modelo encontrado e **salve o modelo** com `joblib.dump` para simular deploy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a67d5096",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sklearn (para os experimentos de ML)\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "# Opção para gráficos inline (no Jupyter/Colab)\n",
    "# %matplotlib inline  # Descomente no Jupyter clássico se necessário\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07ab18ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        model  cv_mean_acc  cv_std_acc  test_acc\n",
      "0  SVC_linear     0.975000    0.033333  1.000000\n",
      "1      LogReg     0.958333    0.026352  0.933333\n",
      "2          RF     0.950000    0.031180  0.900000\n",
      "\n",
      "== Melhor por CV (sem GridSearch): SVC_linear ==\n",
      "Acurácia no teste: 1.000\n",
      "\n",
      "Relatório de classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00        10\n",
      "           2       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "Matriz de confusão:\n",
      " [[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n"
     ]
    }
   ],
   "source": [
    "# Dados\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "# Mesmo esquema de CV da fase com GridSearch\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# Mesmos candidatos do código-base, em Pipeline quando necessário\n",
    "candidates = {\n",
    "    \"LogReg\": Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", LogisticRegression(max_iter=2000, random_state=RANDOM_STATE))\n",
    "    ]),\n",
    "    \"SVC_linear\": Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", SVC(kernel=\"linear\", random_state=RANDOM_STATE))\n",
    "    ]),\n",
    "    \"RF\": RandomForestClassifier(n_estimators=200, random_state=RANDOM_STATE)\n",
    "}\n",
    "\n",
    "# Avaliação com cross_validate para obter média e desvio\n",
    "rows = []\n",
    "for name, model in candidates.items():\n",
    "    cv_res = cross_validate(\n",
    "        model,\n",
    "        X_train, y_train,\n",
    "        cv=cv,\n",
    "        scoring=\"accuracy\",\n",
    "        return_train_score=False,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    cv_mean = cv_res[\"test_score\"].mean()\n",
    "    cv_std  = cv_res[\"test_score\"].std()\n",
    "\n",
    "    # Treina no treino inteiro e mede no teste (coerente com a etapa de GS)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    test_acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    rows.append({\n",
    "        \"model\": name,\n",
    "        \"cv_mean_acc\": cv_mean,\n",
    "        \"cv_std_acc\": cv_std,\n",
    "        \"test_acc\": test_acc\n",
    "    })\n",
    "\n",
    "df_base = pd.DataFrame(rows).sort_values(by=\"cv_mean_acc\", ascending=False).reset_index(drop=True)\n",
    "print(df_base)\n",
    "\n",
    "# Escolhe o melhor por CV médio (mesmo critério da etapa com GridSearch)\n",
    "best_name = df_base.iloc[0][\"model\"]\n",
    "best_model = candidates[best_name]\n",
    "print(f\"\\n== Melhor por CV (sem GridSearch): {best_name} ==\")\n",
    "\n",
    "# Reavalia melhor modelo para relatar detalhes (já treinado acima, mas reforçamos)\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "print(f\"Acurácia no teste: {accuracy_score(y_test, y_pred_best):.3f}\\n\")\n",
    "print(\"Relatório de classificação:\\n\", classification_report(y_test, y_pred_best))\n",
    "print(\"Matriz de confusão:\\n\", confusion_matrix(y_test, y_pred_best))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0602ed0",
   "metadata": {},
   "source": [
    "### Adaptação (Extra)\n",
    "- Use `GridSearchCV` com `cv=StratifiedKFold(5)`.\n",
    "- Defina `param_grid` apropriados. Exemplos:\n",
    "  - **SVC**: `C=[0.1,1,10]`, `kernel=['linear','rbf']`, `gamma=['scale','auto']`\n",
    "  - **RandomForest**: `n_estimators=[100,300]`, `max_depth=[None,5,10]`, `min_samples_split=[2,5]`\n",
    "- Envolva SVC em `Pipeline(StandardScaler(), SVC(...))` para evitar *data leakage*.\n",
    "- Relate `best_params_`, `best_score_` e avalie no teste.\n",
    "- Por fim, salve o melhor modelo com `joblib.dump`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2f8a4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        model                                        best_params  cv_mean_acc  \\\n",
      "0  SVC_linear                                    {'clf__C': 0.1}     0.975000   \n",
      "1      LogReg  {'clf__C': 3, 'clf__penalty': 'l2', 'clf__solv...     0.966667   \n",
      "2          RF  {'max_depth': None, 'min_samples_split': 5, 'n...     0.966667   \n",
      "\n",
      "   test_acc  \n",
      "0  0.933333  \n",
      "1  0.966667  \n",
      "2  0.966667  \n",
      "\n",
      "== Melhor por CV: SVC_linear ==\n",
      "Acurácia no teste: 0.933\n",
      "\n",
      "Relatório de classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       0.90      0.90      0.90        10\n",
      "           2       0.90      0.90      0.90        10\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.93      0.93      0.93        30\n",
      "weighted avg       0.93      0.93      0.93        30\n",
      "\n",
      "Matriz de confusão:\n",
      " [[10  0  0]\n",
      " [ 0  9  1]\n",
      " [ 0  1  9]]\n",
      "\n",
      "Modelo salvo em: melhor_modelo_gridsearch.joblib\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# ===== Mesmos classificadores do código-base, agora com Grids =====\n",
    "# LogReg + scaler\n",
    "pipe_logreg = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(max_iter=2000, random_state=RANDOM_STATE))\n",
    "])\n",
    "grid_logreg = {\n",
    "    \"clf__C\": [0.1, 1, 3, 10],\n",
    "    \"clf__penalty\": [\"l2\"],                # (l1 requer solver 'liblinear' e sem multi_class='multinomial')\n",
    "    \"clf__solver\": [\"lbfgs\", \"liblinear\"], # ambos funcionam com l2\n",
    "}\n",
    "\n",
    "# SVC linear + scaler (mantendo kernel linear como no seu base)\n",
    "pipe_svc_lin = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", SVC(kernel=\"linear\", random_state=RANDOM_STATE))\n",
    "])\n",
    "grid_svc_lin = {\n",
    "    \"clf__C\": [0.1, 1, 3, 10]\n",
    "}\n",
    "\n",
    "# RandomForest (não precisa de scaler)\n",
    "rf = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "grid_rf = {\n",
    "    \"n_estimators\": [100, 200, 400],\n",
    "    \"max_depth\": [None, 5, 10],\n",
    "    \"min_samples_split\": [2, 5]\n",
    "}\n",
    "\n",
    "# Empacotar tudo\n",
    "search_space = [\n",
    "    (\"LogReg\",    pipe_logreg, grid_logreg),\n",
    "    (\"SVC_linear\", pipe_svc_lin, grid_svc_lin),\n",
    "    (\"RF\",        rf,          grid_rf),\n",
    "]\n",
    "\n",
    "results = []\n",
    "best_global = None\n",
    "best_global_name = None\n",
    "best_global_cv = -np.inf\n",
    "\n",
    "for name, estimator, param_grid in search_space:\n",
    "    gs = GridSearchCV(\n",
    "        estimator=estimator,\n",
    "        param_grid=param_grid,\n",
    "        cv=cv,\n",
    "        scoring=\"accuracy\",\n",
    "        n_jobs=-1,\n",
    "        refit=True,\n",
    "        return_train_score=False,\n",
    "    )\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    # Avaliação em teste\n",
    "    y_pred = gs.best_estimator_.predict(X_test)\n",
    "    test_acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    results.append({\n",
    "        \"model\": name,\n",
    "        \"best_params\": gs.best_params_,\n",
    "        \"cv_mean_acc\": gs.best_score_,\n",
    "        \"test_acc\": test_acc\n",
    "    })\n",
    "\n",
    "    # Guardar \"melhor por CV\"\n",
    "    if gs.best_score_ > best_global_cv:\n",
    "        best_global_cv = gs.best_score_\n",
    "        best_global = gs.best_estimator_\n",
    "        best_global_name = name\n",
    "\n",
    "# Mostrar ranking\n",
    "df_results = pd.DataFrame(results).sort_values(by=\"cv_mean_acc\", ascending=False).reset_index(drop=True)\n",
    "print(df_results)\n",
    "\n",
    "print(f\"\\n== Melhor por CV: {best_global_name} ==\")\n",
    "y_pred_best = best_global.predict(X_test)\n",
    "print(f\"Acurácia no teste: {accuracy_score(y_test, y_pred_best):.3f}\\n\")\n",
    "print(\"Relatório de classificação:\\n\", classification_report(y_test, y_pred_best))\n",
    "print(\"Matriz de confusão:\\n\", confusion_matrix(y_test, y_pred_best))\n",
    "\n",
    "# Salvar melhor modelo (simulação de deploy)\n",
    "joblib.dump(best_global, \"melhor_modelo_gridsearch.joblib\")\n",
    "print(\"\\nModelo salvo em: melhor_modelo_gridsearch.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
